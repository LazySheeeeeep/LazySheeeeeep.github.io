---
title: "V2P-Bench: Evaluating Video-Language Understanding with Visual Prompts for Better Human-Model Interaction"
collection: publications
date: 2025-03-01
venue: "Preprint, 2025"
authors: "Yiming Zhao, Yu Zeng, Yukun Qi, YaoYang Liu, Lin Chen, Zehui Chen, Xikun Bao, Jie Zhao, Feng Zhao"
arxiv: "https://arxiv.org/abs/2503.17736"
project: "https://vlm-reasoning.github.io/V2P-Bench/"
code: "https://github.com/gaotiexinqu/V2P-Bench"
excerpt: "V2P-Bench is a comprehensive benchmark specifically designed to evaluate the video understanding capabilities of LVLMs in human-model interaction scenarios."
thumbnail: "/images/V2P-Bench.png"
---
